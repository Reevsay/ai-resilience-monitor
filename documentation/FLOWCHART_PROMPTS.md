# Flowchart Creation Prompts - AI Resilience Monitor Procedures
**Date:** October 6, 2025  
**Project:** AI Service Resilience Monitor  
**Total Procedures:** 4 Core Procedures

---

## How to Use These Prompts

### **Option 1: AI Tools (ChatGPT, Claude, etc.)**
Copy the prompt â†’ Paste into ChatGPT/Claude â†’ Request Mermaid diagram code â†’ Paste code into https://mermaid.live/ â†’ Export as PNG

### **Option 2: Draw.io / Lucidchart**
Use the detailed steps in each prompt to manually create flowchart

### **Option 3: PowerPoint / Google Slides**
Follow the component descriptions to build flowchart using shapes

---

## Procedure 1: Circuit Breaker Pattern

### ðŸŽ¨ AI Prompt for Flowchart Generation

```
Create a detailed flowchart for a Circuit Breaker pattern used in an AI service resilience monitoring system. The flowchart should show:

START
â†“
[Input: Service Name, API Request]
â†“
{Decision: Check Circuit State}
â”œâ”€ If CLOSED:
â”‚   â†“
â”‚   [Execute API Request to AI Service]
â”‚   â†“
â”‚   {Decision: Request Successful?}
â”‚   â”œâ”€ Yes:
â”‚   â”‚   â†“
â”‚   â”‚   [Reset Failure Count = 0]
â”‚   â”‚   â†“
â”‚   â”‚   [Record Success Metrics (latency, timestamp)]
â”‚   â”‚   â†“
â”‚   â”‚   [Return Response to Client]
â”‚   â”‚   â†“
â”‚   â”‚   END
â”‚   â”‚
â”‚   â””â”€ No (Error/Timeout):
â”‚       â†“
â”‚       [Increment Failure Count]
â”‚       â†“
â”‚       [Record Failure Metrics (error type, timestamp)]
â”‚       â†“
â”‚       {Decision: Failure Count >= Threshold (5)?}
â”‚       â”œâ”€ Yes:
â”‚       â”‚   â†“
â”‚       â”‚   [Change State to OPEN]
â”‚       â”‚   â†“
â”‚       â”‚   [Record Last Failure Time]
â”‚       â”‚   â†“
â”‚       â”‚   [Throw Circuit Breaker Error]
â”‚       â”‚   â†“
â”‚       â”‚   END
â”‚       â”‚
â”‚       â””â”€ No:
â”‚           â†“
â”‚           [Keep State CLOSED]
â”‚           â†“
â”‚           [Throw Original Error]
â”‚           â†“
â”‚           END
â”‚
â”œâ”€ If OPEN:
â”‚   â†“
â”‚   [Calculate: Time Since Last Failure]
â”‚   â†“
â”‚   {Decision: Time Elapsed > Timeout (60s)?}
â”‚   â”œâ”€ Yes:
â”‚   â”‚   â†“
â”‚   â”‚   [Change State to HALF_OPEN]
â”‚   â”‚   â†“
â”‚   â”‚   [Allow ONE Test Request]
â”‚   â”‚   â†“
â”‚   â”‚   [Execute API Request]
â”‚   â”‚   â†“
â”‚   â”‚   {Decision: Test Request Successful?}
â”‚   â”‚   â”œâ”€ Yes:
â”‚   â”‚   â”‚   â†“
â”‚   â”‚   â”‚   [Change State to CLOSED]
â”‚   â”‚   â”‚   â†“
â”‚   â”‚   â”‚   [Reset Failure Count = 0]
â”‚   â”‚   â”‚   â†“
â”‚   â”‚   â”‚   [Return Response]
â”‚   â”‚   â”‚   â†“
â”‚   â”‚   â”‚   END
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€ No:
â”‚   â”‚       â†“
â”‚   â”‚       [Keep State OPEN]
â”‚   â”‚       â†“
â”‚   â”‚       [Record Last Failure Time (reset timeout)]
â”‚   â”‚       â†“
â”‚   â”‚       [Throw Error]
â”‚   â”‚       â†“
â”‚   â”‚       END
â”‚   â”‚
â”‚   â””â”€ No:
â”‚       â†“
â”‚       [Block Request Immediately]
â”‚       â†“
â”‚       [Throw "Circuit Breaker Open" Error]
â”‚       â†“
â”‚       END
â”‚
â””â”€ If HALF_OPEN:
    â†“
    [Allow Test Request]
    â†“
    [Execute API Request]
    â†“
    {Decision: Request Successful?}
    â”œâ”€ Yes:
    â”‚   â†“
    â”‚   [Change State to CLOSED]
    â”‚   â†“
    â”‚   [Reset Failure Count]
    â”‚   â†“
    â”‚   [Return Response]
    â”‚   â†“
    â”‚   END
    â”‚
    â””â”€ No:
        â†“
        [Change State back to OPEN]
        â†“
        [Record Last Failure Time]
        â†“
        [Throw Error]
        â†“
        END

Use these symbols:
- START/END: Rounded rectangles (oval)
- Process boxes: Rectangles
- Decisions: Diamonds
- Data: Parallelograms
- Arrows: Solid lines with arrowheads
- States: Bold boxes with colors (CLOSED=Green, OPEN=Red, HALF_OPEN=Yellow)

Color scheme:
- Success paths: Green
- Failure paths: Red
- Decision paths: Blue
- State transitions: Orange

Generate Mermaid flowchart code for this.
```

---

### ðŸ“Š Mermaid Code (Copy-Paste Ready)

```mermaid
flowchart TD
    Start([START: API Request]) --> Input[/"Input: Service Name, Request"/]
    Input --> CheckState{Check Circuit<br/>State}
    
    CheckState -->|CLOSED| ExecReq[Execute API Request]
    ExecReq --> Success{Request<br/>Successful?}
    
    Success -->|Yes| Reset[Reset Failure Count = 0]
    Reset --> RecordSuccess[Record Success Metrics]
    RecordSuccess --> Return1[Return Response]
    Return1 --> End1([END])
    
    Success -->|No| IncFail[Increment Failure Count]
    IncFail --> RecordFail[Record Failure Metrics]
    RecordFail --> CheckThreshold{Failure Count<br/>>= 5?}
    
    CheckThreshold -->|Yes| ToOpen[Change State to OPEN]
    ToOpen --> RecordTime[Record Last Failure Time]
    RecordTime --> ThrowCB[Throw Circuit Breaker Error]
    ThrowCB --> End2([END])
    
    CheckThreshold -->|No| KeepClosed[Keep State CLOSED]
    KeepClosed --> ThrowOrig[Throw Original Error]
    ThrowOrig --> End3([END])
    
    CheckState -->|OPEN| CalcTime[Calculate Time Since Last Failure]
    CalcTime --> CheckTimeout{Time Elapsed<br/>> 60s?}
    
    CheckTimeout -->|Yes| ToHalfOpen[Change State to HALF_OPEN]
    ToHalfOpen --> TestReq[Allow ONE Test Request]
    TestReq --> ExecTest[Execute API Request]
    ExecTest --> TestSuccess{Test Successful?}
    
    TestSuccess -->|Yes| ToClosed1[Change State to CLOSED]
    ToClosed1 --> ResetCount1[Reset Failure Count]
    ResetCount1 --> Return2[Return Response]
    Return2 --> End4([END])
    
    TestSuccess -->|No| StayOpen[Keep State OPEN]
    StayOpen --> ResetTimer[Reset Last Failure Time]
    ResetTimer --> ThrowErr1[Throw Error]
    ThrowErr1 --> End5([END])
    
    CheckTimeout -->|No| BlockReq[Block Request Immediately]
    BlockReq --> ThrowOpen[Throw Circuit Breaker Open Error]
    ThrowOpen --> End6([END])
    
    CheckState -->|HALF_OPEN| AllowTest[Allow Test Request]
    AllowTest --> ExecHalf[Execute API Request]
    ExecHalf --> HalfSuccess{Request<br/>Successful?}
    
    HalfSuccess -->|Yes| ToClosed2[Change State to CLOSED]
    ToClosed2 --> ResetCount2[Reset Failure Count]
    ResetCount2 --> Return3[Return Response]
    Return3 --> End7([END])
    
    HalfSuccess -->|No| BackToOpen[Change State back to OPEN]
    BackToOpen --> RecordTime2[Record Last Failure Time]
    RecordTime2 --> ThrowErr2[Throw Error]
    ThrowErr2 --> End8([END])
    
    style Start fill:#90EE90
    style End1 fill:#90EE90
    style End4 fill:#90EE90
    style End7 fill:#90EE90
    style End2 fill:#FFB6C1
    style End3 fill:#FFB6C1
    style End5 fill:#FFB6C1
    style End6 fill:#FFB6C1
    style End8 fill:#FFB6C1
    style ToOpen fill:#FF6B6B
    style ToClosed1 fill:#51CF66
    style ToClosed2 fill:#51CF66
    style ToHalfOpen fill:#FFD93D
```

---

## Procedure 2: Metrics Collection & Aggregation

### ðŸŽ¨ AI Prompt for Flowchart Generation

```
Create a flowchart for the Metrics Collection and Aggregation procedure in an AI resilience monitoring system. Show:

START
â†“
[Trigger: Timer (5-second interval) OR API Call]
â†“
[Initialize Empty Metrics Object]
â†“
[Get Current Timestamp]
â†“
[Read metricsHistory from Backend]
â†“
[Process: Calculate Total Requests]
â”œâ”€ totalRequests = metricsHistory.totalRequests
â†“
[Process: Calculate Successful Requests]
â”œâ”€ successfulRequests = metricsHistory.successfulRequests
â†“
[Process: Calculate Failed Requests]
â”œâ”€ failedRequests = metricsHistory.failedRequests
â†“
[Calculate: Success Rate %]
â”œâ”€ successRate = (successfulRequests / totalRequests) Ã— 100
â†“
[Calculate: Average Latency]
â”œâ”€ avgLatency = totalLatency / successfulRequests
â†“
[Calculate: System Uptime]
â”œâ”€ uptime = currentTime - serverStartTime
â†“
[Loop: For Each AI Service (Gemini, Cohere, Hugging Face)]
â”‚
â”œâ”€ [Get Service-Specific Data]
â”‚   â”œâ”€ service.requests
â”‚   â”œâ”€ service.failures
â”‚   â”œâ”€ service.successRate
â”‚   â”œâ”€ service.avgLatency
â”‚   â”œâ”€ service.status (up/down)
â”‚   â†“
â”œâ”€ [Calculate Service Health Score]
â”‚   â”œâ”€ uptimeScore = (uptime / maxUptime) Ã— 40
â”‚   â”œâ”€ successScore = (successRate / 100) Ã— 40
â”‚   â”œâ”€ speedScore = (1 - avgLatency / maxLatency) Ã— 20
â”‚   â”œâ”€ healthScore = uptimeScore + successScore + speedScore
â”‚   â†“
â”œâ”€ [Store Service Metrics in Object]
â”‚   â””â”€ aiServices[serviceName] = {health, latency, success, status}
â†“
[Aggregate All Metrics into Response Object]
â”œâ”€ {
â”‚     totalRequests,
â”‚     successfulRequests,
â”‚     failedRequests,
â”‚     successRate,
â”‚     avgLatency,
â”‚     uptime,
â”‚     aiServices: {...}
â”‚   }
â†“
[Send Metrics to Frontend Dashboard]
â†“
[Update Charts and Health Scores]
â†“
[Store in localStorage (last 500 requests)]
â†“
END

Use standard flowchart symbols with color coding for different metric types.
Generate Mermaid code.
```

---

### ðŸ“Š Mermaid Code (Copy-Paste Ready)

```mermaid
flowchart TD
    Start([START: Metrics Collection]) --> Trigger[Trigger: 5s Timer OR API Call]
    Trigger --> Init[Initialize Empty Metrics Object]
    Init --> GetTime[Get Current Timestamp]
    GetTime --> ReadHist[Read metricsHistory from Backend]
    
    ReadHist --> CalcTotal[Calculate Total Requests<br/>totalRequests = metricsHistory.totalRequests]
    CalcTotal --> CalcSuccess[Calculate Successful Requests<br/>successfulRequests = metricsHistory.successfulRequests]
    CalcSuccess --> CalcFail[Calculate Failed Requests<br/>failedRequests = metricsHistory.failedRequests]
    
    CalcFail --> CalcRate[Calculate Success Rate<br/>successRate = successful / total Ã— 100]
    CalcRate --> CalcLatency[Calculate Avg Latency<br/>avgLatency = totalLatency / successful]
    CalcLatency --> CalcUptime[Calculate System Uptime<br/>uptime = now - startTime]
    
    CalcUptime --> LoopStart{For Each AI Service}
    LoopStart -->|Gemini| GetService1[Get Service Data]
    LoopStart -->|Cohere| GetService2[Get Service Data]
    LoopStart -->|HuggingFace| GetService3[Get Service Data]
    
    GetService1 --> CalcHealth1[Calculate Health Score]
    GetService2 --> CalcHealth2[Calculate Health Score]
    GetService3 --> CalcHealth3[Calculate Health Score]
    
    CalcHealth1 --> Store1[Store in aiServices Object]
    CalcHealth2 --> Store2[Store in aiServices Object]
    CalcHealth3 --> Store3[Store in aiServices Object]
    
    Store1 --> Aggregate[Aggregate All Metrics]
    Store2 --> Aggregate
    Store3 --> Aggregate
    
    Aggregate --> Response[Build Response Object:<br/>totalRequests, successRate,<br/>avgLatency, uptime, aiServices]
    Response --> Send[Send Metrics to Frontend]
    Send --> Update[Update Dashboard Charts & Scores]
    Update --> LocalStore[Store in localStorage<br/>last 500 requests]
    LocalStore --> End([END])
    
    style Start fill:#4ECDC4
    style End fill:#4ECDC4
    style CalcRate fill:#FFE66D
    style CalcHealth1 fill:#FF6B6B
    style CalcHealth2 fill:#FF6B6B
    style CalcHealth3 fill:#FF6B6B
    style Update fill:#95E1D3
```

---

## Procedure 3: Health Score Calculation

### ðŸŽ¨ AI Prompt for Flowchart Generation

```
Create a flowchart for AI Service Health Score Calculation with a weighted scoring algorithm (40% uptime + 40% success rate + 20% speed). Show:

START
â†“
[Input: Service Name (Gemini/Cohere/HuggingFace)]
â†“
[Fetch Service Metrics from Backend]
â”œâ”€ currentUptime (seconds)
â”œâ”€ successRate (percentage)
â”œâ”€ avgLatency (milliseconds)
â”œâ”€ totalRequests
â†“
{Decision: Has Service Been Tested?}
â”œâ”€ No (totalRequests = 0):
â”‚   â†“
â”‚   [Set Health Score = 0]
â”‚   â†“
â”‚   [Set Status = "Not Tested"]
â”‚   â†“
â”‚   [Return Score]
â”‚   â†“
â”‚   END
â”‚
â””â”€ Yes (totalRequests > 0):
    â†“
    [Component 1: Calculate Uptime Score]
    â”œâ”€ maxExpectedUptime = currentSessionDuration
    â”œâ”€ uptimePercentage = (currentUptime / maxExpectedUptime) Ã— 100
    â”œâ”€ uptimeScore = uptimePercentage Ã— 0.40
    â†“
    [Component 2: Calculate Success Score]
    â”œâ”€ successScore = successRate Ã— 0.40
    â†“
    [Component 3: Calculate Speed Score]
    â”œâ”€ maxAcceptableLatency = 5000ms (benchmark)
    â”œâ”€ speedPercentage = ((maxLatency - avgLatency) / maxLatency) Ã— 100
    â”œâ”€ speedScore = speedPercentage Ã— 0.20
    â†“
    [Aggregate: Calculate Total Health Score]
    â”œâ”€ healthScore = uptimeScore + successScore + speedScore
    â†“
    [Normalize: Ensure Score is 0-100]
    â”œâ”€ healthScore = Math.max(0, Math.min(100, healthScore))
    â†“
    {Decision: Categorize Health Level}
    â”œâ”€ If healthScore >= 80:
    â”‚   â†“
    â”‚   [Set Status = "Excellent" (Green)]
    â”‚
    â”œâ”€ If healthScore >= 60:
    â”‚   â†“
    â”‚   [Set Status = "Good" (Yellow)]
    â”‚
    â”œâ”€ If healthScore >= 40:
    â”‚   â†“
    â”‚   [Set Status = "Warning" (Orange)]
    â”‚
    â””â”€ If healthScore < 40:
        â†“
        [Set Status = "Critical" (Red)]
    â†“
    [Update Service Health Badge in Dashboard]
    â†“
    [Update Health Bar Chart]
    â†“
    [Log Health Score to Analytics]
    â†“
    [Return: {healthScore, status, breakdown: {uptime, success, speed}}]
    â†“
    END

Use color-coded status indicators and show the 40-40-20 weighting visually.
Generate Mermaid code.
```

---

### ðŸ“Š Mermaid Code (Copy-Paste Ready)

```mermaid
flowchart TD
    Start([START: Health Score Calculation]) --> Input[/"Input: Service Name<br/>(Gemini/Cohere/HuggingFace)"/]
    Input --> Fetch[Fetch Service Metrics:<br/>uptime, successRate, avgLatency]
    
    Fetch --> Check{Has Service<br/>Been Tested?<br/>totalRequests > 0?}
    
    Check -->|No| SetZero[Set Health Score = 0]
    SetZero --> SetNotTested[Set Status = Not Tested]
    SetNotTested --> Return1[Return Score]
    Return1 --> End1([END])
    
    Check -->|Yes| CalcUptime[Component 1: Uptime Score 40%<br/>uptimeScore = uptime / sessionDuration Ã— 40]
    CalcUptime --> CalcSuccess[Component 2: Success Score 40%<br/>successScore = successRate Ã— 0.40]
    CalcSuccess --> CalcSpeed[Component 3: Speed Score 20%<br/>speedScore = 1 - avgLatency/5000 Ã— 20]
    
    CalcSpeed --> Aggregate[Aggregate Total Health Score<br/>healthScore = uptime + success + speed]
    Aggregate --> Normalize[Normalize: 0 â‰¤ score â‰¤ 100]
    
    Normalize --> Categorize{Categorize<br/>Health Level}
    
    Categorize -->|score >= 80| Excellent[Status = EXCELLENT<br/>Color: Green]
    Categorize -->|60 <= score < 80| Good[Status = GOOD<br/>Color: Yellow]
    Categorize -->|40 <= score < 60| Warning[Status = WARNING<br/>Color: Orange]
    Categorize -->|score < 40| Critical[Status = CRITICAL<br/>Color: Red]
    
    Excellent --> Update[Update Dashboard Health Badge]
    Good --> Update
    Warning --> Update
    Critical --> Update
    
    Update --> Chart[Update Health Bar Chart]
    Chart --> Log[Log Health Score to Analytics]
    Log --> Return2[/"Return: {healthScore, status,<br/>breakdown: {uptime, success, speed}}"/]
    Return2 --> End2([END])
    
    style Start fill:#A8E6CF
    style End1 fill:#FFD3B6
    style End2 fill:#A8E6CF
    style CalcUptime fill:#FFAAA5
    style CalcSuccess fill:#FF8B94
    style CalcSpeed fill:#FFDAC1
    style Excellent fill:#51CF66
    style Good fill:#FFD93D
    style Warning fill:#FF922B
    style Critical fill:#FF6B6B
```

---

## Procedure 4: Automated Chaos Testing

### ðŸŽ¨ AI Prompt for Flowchart Generation

```
Create a flowchart for Automated Chaos Testing procedure that continuously tests AI service resilience. Show:

START
â†“
[System Initialization]
â†“
[Load Configuration]
â”œâ”€ testInterval = 10 seconds (configurable)
â”œâ”€ enabledServices = [Gemini, Cohere, HuggingFace]
â”œâ”€ testPrompts = ["Test prompt 1", "Test prompt 2", ...]
â†“
[Start Automated Testing Loop]
â†“
[Wait for Next Interval (10 seconds)]
â†“
[Select Random Service]
â”œâ”€ services = [Gemini, Cohere, HuggingFace]
â”œâ”€ selectedService = random(services)
â†“
[Select Random Test Prompt]
â”œâ”€ prompts = ["Simple test", "Complex query", ...]
â”œâ”€ testPrompt = random(prompts)
â†“
[Record Start Time]
â†“
[Generate Request ID (UUID)]
â†“
[Check Circuit Breaker State for Selected Service]
â†“
{Decision: Circuit Breaker Open?}
â”œâ”€ Yes:
â”‚   â†“
â”‚   [Skip API Call]
â”‚   â†“
â”‚   [Log: "Request Blocked - Circuit Open"]
â”‚   â†“
â”‚   [Record Failure Metrics]
â”‚   â”œâ”€ timestamp
â”‚   â”œâ”€ service
â”‚   â”œâ”€ status = "blocked"
â”‚   â”œâ”€ errorType = "Circuit Breaker Open"
â”‚   â†“
â”‚   [Update Dashboard with Blocked Request]
â”‚   â†“
â”‚   [Go to Next Interval] â”€â”€â”€â”
â”‚                            â”‚
â””â”€ No:                       â”‚
    â†“                        â”‚
    [Execute API Request]    â”‚
    â”œâ”€ Send POST to /ai endpoint
    â”œâ”€ Include: service, prompt
    â†“                        â”‚
    {Decision: Request Successful?}
    â”‚                        â”‚
    â”œâ”€ Yes:                  â”‚
    â”‚   â†“                    â”‚
    â”‚   [Record End Time]    â”‚
    â”‚   â†“                    â”‚
    â”‚   [Calculate Latency = endTime - startTime]
    â”‚   â†“                    â”‚
    â”‚   [Extract Response Data]
    â”‚   â”œâ”€ responseText     â”‚
    â”‚   â”œâ”€ responseSize     â”‚
    â”‚   â†“                    â”‚
    â”‚   [Log Success Metrics]
    â”‚   â”œâ”€ timestamp        â”‚
    â”‚   â”œâ”€ service          â”‚
    â”‚   â”œâ”€ latency (ms)     â”‚
    â”‚   â”œâ”€ status = "success"
    â”‚   â”œâ”€ responseSize     â”‚
    â”‚   â†“                    â”‚
    â”‚   [Update Success Counter]
    â”‚   â†“                    â”‚
    â”‚   [Update Latency Chart]
    â”‚   â†“                    â”‚
    â”‚   [Update Health Score Dashboard]
    â”‚   â†“                    â”‚
    â”‚   [Store in Request History (last 500)]
    â”‚   â†“                    â”‚
    â”‚   [Go to Next Interval] â”€â”¤
    â”‚                          â”‚
    â””â”€ No (Error/Timeout):     â”‚
        â†“                      â”‚
        [Record End Time]      â”‚
        â†“                      â”‚
        [Calculate Latency]    â”‚
        â†“                      â”‚
        [Extract Error Details]
        â”œâ”€ errorType (timeout, 500, rate limit, etc.)
        â”œâ”€ errorMessage        â”‚
        â†“                      â”‚
        [Log Failure Metrics]  â”‚
        â”œâ”€ timestamp           â”‚
        â”œâ”€ service             â”‚
        â”œâ”€ latency             â”‚
        â”œâ”€ status = "failure"  â”‚
        â”œâ”€ errorType           â”‚
        â”œâ”€ errorMessage        â”‚
        â†“                      â”‚
        [Update Failure Counter]
        â†“                      â”‚
        [Update Error Leaderboard]
        â†“                      â”‚
        [Trigger Circuit Breaker Logic]
        â†“                      â”‚
        [Update Dashboard with Error]
        â†“                      â”‚
        [Store in Request History]
        â†“                      â”‚
        [Go to Next Interval] â”€â”˜
        â†“
[Check: Continue Testing?]
â”œâ”€ If autoTesting enabled: Loop back to "Wait for Next Interval"
â””â”€ If stopped: END

Show the continuous loop nature and error handling paths clearly.
Generate Mermaid code.
```

---

### ðŸ“Š Mermaid Code (Copy-Paste Ready)

```mermaid
flowchart TD
    Start([START: Automated Chaos Testing]) --> Init[System Initialization]
    Init --> LoadConfig[Load Configuration:<br/>interval=10s, services, prompts]
    LoadConfig --> LoopStart[Start Automated Testing Loop]
    
    LoopStart --> Wait[Wait for Next Interval 10s]
    Wait --> SelectService[Select Random Service<br/>Gemini/Cohere/HuggingFace]
    SelectService --> SelectPrompt[Select Random Test Prompt]
    SelectPrompt --> RecordStart[Record Start Time]
    RecordStart --> GenID[Generate Request ID UUID]
    GenID --> CheckCB{Circuit Breaker<br/>Open?}
    
    CheckCB -->|Yes| Skip[Skip API Call]
    Skip --> LogBlock[Log: Request Blocked - Circuit Open]
    LogBlock --> RecordBlock[Record Failure Metrics:<br/>timestamp, service, status=blocked]
    RecordBlock --> UpdateBlock[Update Dashboard with Blocked]
    UpdateBlock --> Continue1[Go to Next Interval]
    
    CheckCB -->|No| Execute[Execute API Request<br/>POST /ai endpoint]
    Execute --> ReqSuccess{Request<br/>Successful?}
    
    ReqSuccess -->|Yes| RecordEnd1[Record End Time]
    RecordEnd1 --> CalcLatency1[Calculate Latency<br/>endTime - startTime]
    CalcLatency1 --> Extract1[Extract Response Data:<br/>text, size]
    Extract1 --> LogSuccess[Log Success Metrics:<br/>timestamp, service, latency, status]
    LogSuccess --> IncSuccess[Update Success Counter]
    IncSuccess --> UpdateChart1[Update Latency Chart]
    UpdateChart1 --> UpdateHealth1[Update Health Score Dashboard]
    UpdateHealth1 --> Store1[Store in Request History<br/>last 500 requests]
    Store1 --> Continue2[Go to Next Interval]
    
    ReqSuccess -->|No| RecordEnd2[Record End Time]
    RecordEnd2 --> CalcLatency2[Calculate Latency]
    CalcLatency2 --> Extract2[Extract Error Details:<br/>errorType, message]
    Extract2 --> LogFail[Log Failure Metrics:<br/>timestamp, service, latency,<br/>status=failure, errorType]
    LogFail --> IncFail[Update Failure Counter]
    IncFail --> UpdateError[Update Error Leaderboard]
    UpdateError --> TriggerCB[Trigger Circuit Breaker Logic]
    TriggerCB --> UpdateDash2[Update Dashboard with Error]
    UpdateDash2 --> Store2[Store in Request History]
    Store2 --> Continue3[Go to Next Interval]
    
    Continue1 --> CheckContinue{Continue<br/>Testing?}
    Continue2 --> CheckContinue
    Continue3 --> CheckContinue
    
    CheckContinue -->|Enabled| Wait
    CheckContinue -->|Stopped| End([END])
    
    style Start fill:#A8DADC
    style End fill:#A8DADC
    style Execute fill:#457B9D
    style LogSuccess fill:#51CF66
    style LogFail fill:#FF6B6B
    style CheckCB fill:#F1FAEE
    style CheckContinue fill:#F1FAEE
```

---

## Procedure 5: Predictive Failure Detection (ML-Based) - PROPOSED

### ðŸŽ¨ AI Prompt for Flowchart Generation

```
Create a flowchart for a Machine Learning-based Predictive Failure Detection system using Z-score anomaly detection. Show:

START
â†“
[Trigger: New Metrics Received from Backend]
â†“
[Fetch Latency Time Series Data]
â”œâ”€ Get last 50 latency measurements for each service
â†“
[Loop: For Each AI Service]
â”‚
â”œâ”€ [Extract Recent Latency Window]
â”‚   â”œâ”€ recentLatencies = last 20 measurements
â”‚   â†“
â”œâ”€ {Decision: Enough Data Points?}
â”‚   â”œâ”€ No (< 20 data points):
â”‚   â”‚   â†“
â”‚   â”‚   [Skip Prediction - Insufficient Data]
â”‚   â”‚   â†“
â”‚   â”‚   [Continue to Next Service]
â”‚   â”‚
â”‚   â””â”€ Yes (>= 20 data points):
â”‚       â†“
â”‚       [Calculate Statistical Features]
â”‚       â”œâ”€ mean = average(recentLatencies)
â”‚       â”œâ”€ stdDev = standardDeviation(recentLatencies)
â”‚       â”œâ”€ currentLatency = latest measurement
â”‚       â†“
â”‚       [Calculate Z-Score]
â”‚       â”œâ”€ zScore = (currentLatency - mean) / stdDev
â”‚       â†“
â”‚       {Decision: Anomaly Detected?}
â”‚       â”‚
â”‚       â”œâ”€ If |zScore| > 3 (3-sigma rule):
â”‚       â”‚   â†“
â”‚       â”‚   [ANOMALY DETECTED]
â”‚       â”‚   â†“
â”‚       â”‚   [Classify Anomaly Severity]
â”‚       â”‚   â”œâ”€ If zScore > 3: "High Latency Spike"
â”‚       â”‚   â”œâ”€ If zScore < -3: "Unusual Fast Response"
â”‚       â”‚   â†“
â”‚       â”‚   [Calculate Failure Probability]
â”‚       â”‚   â”œâ”€ probability = |zScore| / 5 (normalized)
â”‚       â”‚   â†“
â”‚       â”‚   [Generate Alert]
â”‚       â”‚   â”œâ”€ alertType = "Predictive Failure Warning"
â”‚       â”‚   â”œâ”€ message = "Service X showing abnormal latency (Z=4.2)"
â”‚       â”‚   â”œâ”€ probability = 84%
â”‚       â”‚   â†“
â”‚       â”‚   {Decision: Preemptive Action Required?}
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€ If probability > 80% AND trend is degrading:
â”‚       â”‚   â”‚   â†“
â”‚       â”‚   â”‚   [Preemptive Circuit Breaker Open]
â”‚       â”‚   â”‚   â†“
â”‚       â”‚   â”‚   [Send Alert to Dashboard]
â”‚       â”‚   â”‚   â”œâ”€ Show warning banner
â”‚       â”‚   â”‚   â”œâ”€ Highlight service in red
â”‚       â”‚   â”‚   â†“
â”‚       â”‚   â”‚   [Log Preemptive Action]
â”‚       â”‚   â”‚   â”œâ”€ timestamp
â”‚       â”‚   â”‚   â”œâ”€ service
â”‚       â”‚   â”‚   â”œâ”€ action = "Preemptive CB Open"
â”‚       â”‚   â”‚   â”œâ”€ zScore
â”‚       â”‚   â”‚   â”œâ”€ probability
â”‚       â”‚   â”‚   â†“
â”‚       â”‚   â”‚   [Continue to Next Service]
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€ Else (probability < 80%):
â”‚       â”‚       â†“
â”‚       â”‚       [Send Warning Only (No CB Action)]
â”‚       â”‚       â†“
â”‚       â”‚       [Update Dashboard Trend Indicator]
â”‚       â”‚       â”œâ”€ Show "Degrading" status
â”‚       â”‚       â†“
â”‚       â”‚       [Continue to Next Service]
â”‚       â”‚
â”‚       â””â”€ If |zScore| <= 3 (Normal):
â”‚           â†“
â”‚           [Calculate Trend Direction]
â”‚           â”œâ”€ Compare last 10 vs previous 10 latencies
â”‚           â”œâ”€ If improving: trend = "improving"
â”‚           â”œâ”€ If stable: trend = "stable"
â”‚           â”œâ”€ If degrading: trend = "degrading"
â”‚           â†“
â”‚           [Update Dashboard Trend Indicator]
â”‚           â†“
â”‚           [Continue to Next Service]
â†“
[All Services Processed]
â†“
[Update ML Model Metrics Dashboard]
â”œâ”€ Show Z-scores per service
â”œâ”€ Show trend indicators
â”œâ”€ Show anomaly count
â†“
[Store Predictions in Analytics]
â†“
[Schedule Next Prediction Cycle (every 30s)]
â†“
END

Include ML-specific elements like feature calculation and model inference.
Generate Mermaid code.
```

---

### ðŸ“Š Mermaid Code (Copy-Paste Ready)

```mermaid
flowchart TD
    Start([START: Predictive Failure Detection]) --> Trigger[Trigger: New Metrics Received]
    Trigger --> Fetch[Fetch Latency Time Series<br/>Last 50 measurements per service]
    
    Fetch --> Loop[Loop: For Each AI Service]
    Loop --> Extract[Extract Recent Window<br/>last 20 latency measurements]
    
    Extract --> CheckData{Enough Data?<br/>>= 20 points}
    CheckData -->|No| Skip[Skip Prediction<br/>Insufficient Data]
    Skip --> NextService1[Continue to Next Service]
    
    CheckData -->|Yes| CalcStats[Calculate Statistical Features:<br/>mean, stdDev, currentLatency]
    CalcStats --> CalcZ[Calculate Z-Score<br/>z = current - mean / stdDev]
    
    CalcZ --> CheckAnomaly{Anomaly<br/>Detected?<br/>z > 3}
    
    CheckAnomaly -->|Yes| Detected[ANOMALY DETECTED]
    Detected --> Classify[Classify Severity:<br/>High Spike z>3 OR Fast z<-3]
    Classify --> CalcProb[Calculate Failure Probability<br/>prob = z / 5 normalized]
    CalcProb --> GenAlert[Generate Alert:<br/>Predictive Failure Warning]
    
    GenAlert --> PreemptCheck{Preemptive<br/>Action<br/>Required?<br/>prob > 80%}
    
    PreemptCheck -->|Yes| PreemptCB[Preemptive Circuit Breaker OPEN]
    PreemptCB --> SendAlert[Send Alert to Dashboard:<br/>warning banner, red highlight]
    SendAlert --> LogAction[Log Preemptive Action:<br/>timestamp, service, zScore, prob]
    LogAction --> NextService2[Continue to Next Service]
    
    PreemptCheck -->|No| WarnOnly[Send Warning Only<br/>No Circuit Breaker Action]
    WarnOnly --> UpdateWarn[Update Dashboard:<br/>Show Degrading Status]
    UpdateWarn --> NextService3[Continue to Next Service]
    
    CheckAnomaly -->|No| CalcTrend[Calculate Trend Direction:<br/>Compare last 10 vs prev 10]
    CalcTrend --> UpdateTrend[Update Dashboard Trend:<br/>improving/stable/degrading]
    UpdateTrend --> NextService4[Continue to Next Service]
    
    NextService1 --> AllDone{All Services<br/>Processed?}
    NextService2 --> AllDone
    NextService3 --> AllDone
    NextService4 --> AllDone
    
    AllDone -->|No| Loop
    AllDone -->|Yes| UpdateML[Update ML Metrics Dashboard:<br/>Z-scores, trends, anomaly count]
    UpdateML --> Store[Store Predictions in Analytics]
    Store --> Schedule[Schedule Next Cycle<br/>every 30 seconds]
    Schedule --> End([END])
    
    style Start fill:#E3F2FD
    style End fill:#E3F2FD
    style Detected fill:#FFCDD2
    style PreemptCB fill:#FF6B6B
    style CalcZ fill:#B39DDB
    style CalcTrend fill:#A5D6A7
```

---

## Quick Reference: Flowchart Symbols

### Standard Symbols:
- **Oval (Rounded Rectangle):** START / END
- **Rectangle:** Process / Action
- **Diamond:** Decision / Condition
- **Parallelogram:** Input / Output / Data
- **Cylinder:** Database / Storage
- **Circle:** Connection point
- **Arrow:** Flow direction

### Color Coding:
- ðŸŸ¢ **Green:** Success paths, positive outcomes
- ðŸ”´ **Red:** Failures, errors, critical states
- ðŸŸ¡ **Yellow:** Warnings, pending states
- ðŸ”µ **Blue:** Neutral processes, calculations
- ðŸŸ  **Orange:** State transitions, important decisions

---

## Tools for Creating Flowcharts

### **1. Mermaid Live Editor (Recommended)**
- URL: https://mermaid.live/
- Copy Mermaid code from above
- Paste into editor
- Export as PNG/SVG

### **2. Draw.io (Desktop/Web)**
- URL: https://app.diagrams.net/
- Free, powerful, professional
- Manual creation using drag-drop

### **3. Lucidchart**
- URL: https://www.lucidchart.com/
- Professional diagramming tool
- Templates available

### **4. Microsoft PowerPoint**
- Use Insert â†’ Shapes
- SmartArt for quick diagrams
- Export as image

### **5. ChatGPT / Claude**
- Copy prompts above
- Ask for Mermaid code
- Paste into Mermaid Live

---

## Next Steps

1. âœ… **Copy Mermaid code** for each procedure
2. âœ… **Paste into https://mermaid.live/**
3. âœ… **Export as PNG** (300 DPI recommended)
4. âœ… **Insert into documentation**
5. âœ… **Create algorithms & pseudo code** (see next document)

---

**All 4 flowcharts ready to generate! Use the Mermaid code sections for instant results.** ðŸš€
