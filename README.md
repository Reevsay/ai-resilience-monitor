# ğŸ¤– AI Resilience Monitor

<div align="center">

![AI Resilience Monitor](https://img.shields.io/badge/AI-Resilience%20Monitor-blue?style=for-the-badge&logo=robot)
![Node.js](https://img.shields.io/badge/Node.js-18+-green?style=for-the-badge&logo=node.js)
![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)
![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)

**ğŸ›¡ï¸ Enterprise-grade AI service monitoring with circuit breakers, failure injection, and real-time resilience testing**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“Š Features](#-features) â€¢ [ğŸ¯ Demo](#-live-demo) â€¢ [ğŸ“š Documentation](#-documentation) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸŒŸ What Makes This Special?

<table>
<tr>
<td width="33%" align="center">
<img src="https://github.com/user-attachments/assets/circuit-breaker-icon" width="80" height="80" alt="Circuit Breaker"/>
<h3>ğŸ”’ Smart Circuit Breakers</h3>
<p>Intelligent failure detection with automatic recovery and fallback mechanisms</p>
</td>
<td width="33%" align="center">
<img src="https://github.com/user-attachments/assets/chaos-engineering-icon" width="80" height="80" alt="Chaos Engineering"/>
<h3>ğŸ’¥ Chaos Engineering</h3>
<p>Advanced failure injection for comprehensive resilience testing</p>
</td>
<td width="33%" align="center">
<img src="https://github.com/user-attachments/assets/dashboard-icon" width="80" height="80" alt="Real-time Dashboard"/>
<h3>ğŸ“Š Live Dashboard</h3>
<p>Beautiful real-time monitoring with animated charts and metrics</p>
</td>
</tr>
</table>



```bash
# One-command setup
docker compose up --build

# Then visit:
ï¿½ Dashboard: http://localhost:3000/dashboard
ğŸ“Š Metrics: http://localhost:3000/metrics
ğŸ” AI Proxy: http://localhost:3000/ai
```

<details>
<summary>ğŸ¬ <strong>Watch the Dashboard in Action!</strong></summary>

### ğŸ”¥ Real-time Features:
- **Live Request Tracking** with color-coded status indicators
- **Animated Circuit Breaker** visualization  
- **Dynamic Charts** updating every 5 seconds
- **Failure Injection** controls with instant feedback
- **Service Health** monitoring with pulse animations

### ğŸ¨ Visual Highlights:
- **Blue-black gradient** theme with particle effects
- **Smooth animations** and hover interactions
- **Mobile responsive** design
- **Professional glassmorphism** styling

</details>

## âš¡ Quick Start

### ğŸ³ Option 1: Docker (Recommended)
```bash
# Clone the repository
git clone https://github.com/Reevsay/ai-resilience-monitor.git
cd ai-resilience-monitor

# Start everything with Docker
docker compose up --build

# ğŸ‰ That's it! Your services are running:
# ğŸŒ Dashboard: http://localhost:3000/dashboard
# ğŸ“Š Metrics: http://localhost:3000/metrics
```

### ğŸ› ï¸ Option 2: Local Development
```bash
# Install dependencies
npm install

# Set up your AI API keys (optional for demo)
cp .env.example .env
# Edit .env with your API keys

# Start the server
npm start

# Run the interactive demo
npm run dashboard-demo
```

## ğŸ“Š Features

### ğŸ”’ **Resilience & Reliability**
| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ”„ Circuit Breaker | Opossum-based protection with auto-recovery | âœ… |
| ğŸ›¡ï¸ Fallback Handling | Graceful degradation when services fail | âœ… |
| ğŸ” Smart Retry | Exponential backoff with jitter | âœ… |
| âš¡ Load Balancing | Multiple AI service support | âœ… |

### ğŸ’¥ **Chaos Engineering**
| Injection Type | Description | Impact |
|----------------|-------------|--------|
| ğŸŒ Network Errors | Connection resets, timeouts, DNS failures | High |
| ğŸ§  Memory Errors | Out-of-memory simulation | Critical |
| ğŸ” Auth Failures | API key failures (401) | Medium |
| ğŸš¦ Rate Limiting | Service quota exceeded (429) | Medium |
| ğŸŒ Slow Responses | Latency injection (5-30s) | Low |
| ğŸ“Š Data Corruption | Random field removal | Medium |

### ğŸ“Š **Monitoring & Observability**
```mermaid
graph TD
    A[AI Services] --> B[Circuit Breaker]
    B --> C[Metrics Collection]
    C --> D[Prometheus]
    C --> E[Live Dashboard]
    E --> F[Real-time Charts]
    E --> G[Service Health]
    E --> H[Request Logs]
```

## ğŸ® Interactive Dashboard Features

<div align="center">

### ğŸ¨ **Beautiful UI Components**

| Component | Features |
|-----------|----------|
| ğŸ“Š **Live Charts** | Request volume, latency trends, success rates |
| ğŸ”„ **Request Monitor** | Real-time AI service calls with responses |
| ğŸ›ï¸ **Service Cards** | Health status with animated indicators |
| âš¡ **Circuit Breaker** | Visual state with breathing animations |
| ğŸš¨ **Alert Panel** | Live notifications with severity levels |

</div>

## ğŸ§ª Testing & Load Simulation

### ğŸš€ **Built-in Test Suites**
```bash
# Quick health check
npm run test

# Test individual AI services
npm run test-cohere
npm run test-gemini
npm run test-huggingface

# Load testing scenarios
npm run load-test              # Balanced load
npm run load-test-small        # Light testing
npm run load-test-large        # Stress testing

# Chaos engineering
npm run chaos-test             # Random failure injection
```

### ğŸ“ˆ **Load Test Results**
<details>
<summary>ğŸ“Š <strong>Performance Benchmarks</strong></summary>

| Scenario | Requests | Concurrency | Success Rate | Avg Latency |
|----------|----------|-------------|--------------|-------------|
| Light | 50 | 2 | 98.5% | 245ms |
| Medium | 100 | 5 | 96.2% | 312ms |
| Heavy | 500 | 10 | 94.8% | 487ms |
| Stress | 1000 | 20 | 91.3% | 652ms |

</details>

## ğŸ”§ Configuration

### ğŸ›ï¸ **Environment Variables**
```bash
# AI Service Configuration
COHERE_API_KEY=your_cohere_key
GEMINI_API_KEY=your_gemini_key
HUGGINGFACE_API_KEY=your_huggingface_key

# Circuit Breaker Settings
CIRCUIT_TIMEOUT=5000
CIRCUIT_ERROR_THRESHOLD=50
CIRCUIT_RESET_TIMEOUT=30000

# Monitoring
PROMETHEUS_PORT=9090
METRICS_INTERVAL=5000
```

### âš™ï¸ **Advanced Configuration**
<details>
<summary>ğŸ”§ <strong>Customize Circuit Breaker</strong></summary>

```javascript
// src/circuitBreaker.js
const options = {
  timeout: 5000,           // Request timeout
  errorThresholdPercentage: 50,  // Failure threshold
  resetTimeout: 30000,     // Recovery time
  name: 'ai-service',      // Circuit name
  group: 'ai-services'     // Circuit group
};
```

</details>

## ğŸ¯ API Endpoints

### ğŸ”Œ **Core APIs**
| Endpoint | Method | Description | Example |
|----------|--------|-------------|---------|
| `/ai` | POST | AI service proxy | `{"message": "Hello AI!"}` |
| `/metrics` | GET | Prometheus metrics | Raw metrics data |
| `/dashboard` | GET | Monitoring dashboard | Interactive UI |
| `/health` | GET | Service health check | Status information |

### ğŸ§ª **Testing Endpoints**
| Endpoint | Method | Description |
|----------|--------|-------------|
| `/test/inject` | POST | Trigger failure injection |
| `/test/circuit` | GET | Circuit breaker status |
| `/test/load` | POST | Simulate load testing |

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    Client[Client Applications] --> LB[Load Balancer]
    LB --> AI[AI Proxy Service]
    
    AI --> CB[Circuit Breaker]
    CB --> FI[Failure Injector]
    FI --> AS1[Cohere API]
    FI --> AS2[Gemini API]
    FI --> AS3[HuggingFace API]
    
    AI --> MC[Metrics Collector]
    MC --> PR[Prometheus]
    MC --> DB[Dashboard]
    
    AI --> AL[Alert Manager]
    AL --> EM[Email Notifications]
    AL --> SL[Slack Webhooks]
    
    style AI fill:#3b82f6
    style CB fill:#ef4444
    style DB fill:#06b6d4
```

## ğŸ“š Documentation

### ğŸ“– **Detailed Guides**
- [ğŸš€ **Quick Start Guide**](docs/QUICK_START.md) - Get up and running in 5 minutes
- [ğŸ”§ **Configuration**](docs/CONFIGURATION.md) - Advanced setup and customization
- [ğŸ§ª **Testing Guide**](docs/TESTING.md) - Comprehensive testing strategies
- [ğŸ“Š **Monitoring**](docs/MONITORING.md) - Metrics and observability setup
- [ğŸ³ **Docker Guide**](docs/DOCKER.md) - Containerization and orchestration
- [ğŸš€ **Deployment**](docs/DEPLOYMENT.md) - Production deployment strategies


## ğŸ› ï¸ Development

### ğŸƒ **Running Locally**
```bash
# Development mode with hot reload
npm run dev

# Run tests with coverage
npm run test:coverage

# Lint and format code
npm run lint
npm run format

# Build for production
npm run build
```

### ğŸ§ª **Testing**
```bash
# Unit tests
npm run test:unit

# Integration tests
npm run test:integration

# End-to-end tests
npm run test:e2e

# Performance tests
npm run test:performance
```

## ğŸ¤ Contributing

We love contributions! ğŸ‰

### ğŸš€ **Quick Contribution Guide**
1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **ğŸ’¾ Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **ğŸ“¤ Push** to the branch (`git push origin feature/amazing-feature`)
5. **ğŸ”„ Open** a Pull Request

### ğŸ“ **Contribution Areas**
- ğŸ› Bug fixes and improvements
- âœ¨ New features and integrations
- ğŸ“š Documentation enhancements
- ğŸ§ª Test coverage improvements
- ğŸ¨ UI/UX enhancements

## ï¿½ Roadmap

### ğŸš€ **Coming Soon**
- [ ] ğŸ” **Advanced Analytics** - ML-powered anomaly detection
- [ ] ğŸŒ **Multi-Region Support** - Global service distribution
- [ ] ğŸ¤– **AI-Powered Insights** - Intelligent failure prediction
- [ ] ğŸ“± **Mobile App** - Monitoring on the go
- [ ] ğŸ”— **Kubernetes Integration** - Native K8s support

### ğŸ¯ **Future Vision**
- [ ] ğŸŒŸ **AI Service Marketplace** - Plugin ecosystem
- [ ] ğŸ” **Advanced Security** - Zero-trust architecture
- [ ] ğŸ“Š **Custom ML Models** - Train your own monitoring models
- [ ] ğŸŒ **Multi-Cloud** - AWS, Azure, GCP support


### ğŸ¨ **Design Inspiration**
- Modern glassmorphism UI trends
- Netflix's chaos engineering practices
- Google's SRE methodologies

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

### ğŸŒŸ **Star this repository if you found it helpful!** ğŸŒŸ

[![GitHub stars](https://img.shields.io/github/stars/Reevsay/ai-resilience-monitor?style=social)](https://github.com/Reevsay/ai-resilience-monitor/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/Reevsay/ai-resilience-monitor?style=social)](https://github.com/Reevsay/ai-resilience-monitor/network/members)
[![GitHub watchers](https://img.shields.io/github/watchers/Reevsay/ai-resilience-monitor?style=social)](https://github.com/Reevsay/ai-resilience-monitor/watchers)

**Made with â¤ï¸ by [Yash](https://github.com/Reevsay)**

[ğŸ” Back to Top](#-ai-resilience-monitor)

</div>
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001

### 3. Start Locally
```bash
npm start
```

## ğŸ“Š Dashboard Features

### Custom Dashboard (http://localhost:3000)
Our custom-built dashboard provides:

#### Query Interface
- **Dropdown Menu**: Pre-built metric queries
- **Custom Input**: Type any Prometheus metric
- **Live Execution**: Real-time query results

#### Available Metrics
- `ai_requests_total` - Total requests processed
- `ai_fallbacks_total` - Circuit breaker fallbacks
- `ai_failures_total` - Failed requests
- `ai_circuit_state` - Circuit breaker state (0=closed, 1=open, 2=half-open)
- `ai_request_latency_ms_*` - Request latency histograms
- `process_cpu_user_seconds_total` - CPU usage
- `nodejs_heap_size_used_bytes` - Memory usage

#### Visualization Types
- **Stat Panels**: Large number displays with color coding
- **Time Series**: Real-time charts with 20-point history
- **Gauge Panels**: Circuit breaker state with status indicators
- **Auto-refresh**: 5s, 10s, 30s, 1m, or manual

## ğŸ§ª Testing

### Load Testing Commands
```bash
# Quick test (50 requests, 5 concurrent)
npm run load-test-quick

# Stress test (500 requests, 20 concurrent)
npm run load-test-stress

# Duration test (60 seconds with 10s ramp-up)
npm run load-test-duration

# Custom test
node test/load-tester.js --requests 100 --concurrency 10
```

### CI Testing
```bash
# Run all CI tests
npm run ci-test

# Test metrics endpoint
npm run metrics-test
```

## ğŸ”§ Configuration

### Environment Variables

#### Failure Injection Rates (0.0 - 1.0)
```bash
FAIL_RATE=0.1                    # 10% basic failures
DELAY_RATE=0.1                   # 10% delay injection
MIN_DELAY=50                     # Minimum delay (ms)
MAX_DELAY=200                    # Maximum delay (ms)
CORRUPT_RATE=0.05                # 5% data corruption
NETWORK_ERROR_RATE=0.05          # 5% network errors
MEMORY_ERROR_RATE=0.02           # 2% memory errors
AUTH_ERROR_RATE=0.03             # 3% auth errors
RATE_LIMIT_ERROR_RATE=0.02       # 2% rate limit errors
PARTIAL_RESPONSE_RATE=0.05       # 5% partial responses
SLOW_RESPONSE_RATE=0.02          # 2% slow responses
```

#### Service Configuration
```bash
PORT=3000                        # Service port
TEST_MODE=true                   # Enable test mode (echoes requests)
AI_ENDPOINT=https://api.ai.com   # Real AI service endpoint
AI_API_KEY=your-key-here         # AI service API key
```

#### Monitoring & Alerts
```bash
MONITORING_INTERVAL_SEC=30       # Alert check interval
ALERT_FAILURE_RATE=0.5          # Alert when >50% failures
ALERT_FALLBACK_RATE=0.8         # Alert when >80% fallbacks
ALERT_AVG_LATENCY_MS=5000       # Alert when >5s latency
ALERT_CIRCUIT_OPEN_DURATION_SEC=300  # Alert if circuit open >5min
```

#### Notifications
```bash
# Slack
SLACK_WEBHOOK_URL=https://hooks.slack.com/...

# Email (SMTP)
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_USER=your-email@gmail.com
EMAIL_PASS=your-app-password
ALERT_EMAIL_TO=admin@company.com
ALERT_EMAIL_FROM=alerts@company.com
```

## ğŸš¨ Alerting

### Start Alert Monitor
```bash
npm run monitor
```

### Test Notifications
```bash
npm run test-alerts
```

### Alert Conditions
- **High Failure Rate**: >50% requests failing
- **High Fallback Rate**: >80% requests using fallback
- **High Latency**: Average >5 seconds
- **Circuit Stuck Open**: Open for >5 minutes
- **Service Unreachable**: Cannot fetch metrics

## ğŸ“ˆ Metrics Reference

### Custom Metrics
| Metric | Type | Description |
|--------|------|-------------|
| `ai_requests_total` | Counter | Total successful AI requests |
| `ai_fallbacks_total` | Counter | Total fallback responses |
| `ai_failures_total` | Counter | Total failed requests |
| `ai_request_latency_ms` | Histogram | Request latency distribution |
| `ai_circuit_state` | Gauge | Circuit breaker state |

### System Metrics (Auto-collected)
- Process CPU usage
- Memory usage (heap/RSS)
- Event loop lag
- Garbage collection timing
- Active handles/requests

## ğŸ› ï¸ Development

### Project Structure
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js              # Main server
â”‚   â”œâ”€â”€ app.js                # Express app (testable)
â”‚   â”œâ”€â”€ failureInjector.js    # Failure injection utilities
â”‚   â”œâ”€â”€ notificationService.js # Email/Slack alerts
â”‚   â”œâ”€â”€ alertMonitor.js       # Monitoring daemon
â”‚   â””â”€â”€ dashboard.html        # Custom dashboard
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ ci-test.js           # CI pipeline tests
â”‚   â”œâ”€â”€ metrics-test.js      # Metrics validation
â”‚   â””â”€â”€ load-tester.js       # Load testing utility
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci.yml               # GitHub Actions pipeline
â”œâ”€â”€ docker-compose.yml        # Multi-service setup
â”œâ”€â”€ Dockerfile               # Container definition
â””â”€â”€ prometheus.yml           # Prometheus config
```

### Adding New Failure Types
1. Add function to `failureInjector.js`
2. Import in `app.js` and `index.js`
3. Add environment variable parsing
4. Integrate in `unreliableAIService()` function
5. Update docker-compose.yml with new env vars

### Custom Metrics
```javascript
const customMetric = new client.Counter({
  name: 'my_custom_metric',
  help: 'Description of metric'
});

// In your code
customMetric.inc();
```

## ğŸš€ Deployment

### Docker Production
```bash
# Build and push
docker build -t ai-resilience-monitor .
docker push your-registry/ai-resilience-monitor

# Deploy
docker run -d \
  -p 3000:3000 \
  -e FAIL_RATE=0.05 \
  -e SLACK_WEBHOOK_URL=your-webhook \
  your-registry/ai-resilience-monitor
```

### Kubernetes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-resilience-monitor
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-resilience-monitor
  template:
    metadata:
      labels:
        app: ai-resilience-monitor
    spec:
      containers:
      - name: ai-resilience-monitor
        image: your-registry/ai-resilience-monitor
        ports:
        - containerPort: 3000
        env:
        - name: FAIL_RATE
          value: "0.05"
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

**Dashboard not loading:**
- Check if service is running on port 3000
- Verify CORS headers are enabled
- Check browser console for errors

**Metrics showing zero:**
- Ensure TEST_MODE=true is set
- Verify Prometheus is scraping correctly
- Check if requests are actually being made

**Alerts not working:**
- Verify webhook URLs and email credentials
- Check environment variables are set
- Test with `npm run test-alerts`

### Debug Commands
```bash
# Check container logs
docker logs devopsproject-ai-proxy-1

# Check metrics directly
curl http://localhost:3000/metrics

# Test API endpoint
curl -X POST http://localhost:3000/ai \
  -H "Content-Type: application/json" \
  -d '{"message": "test"}'
```

---

**Built with â¤ï¸ for resilient AI systems**
